- Approximate action space somehow
	==> Some maximal amount of flows + granularity of throughput
		==> Or is flow scheduling as simple as choosing which goes first? I imagine some kind of multiplexing must be possible.
	==> Deep Reinforcement Learning uses Deep Neural Network to represent (state, action) spaces 
		--> https://ai.stackexchange.com/questions/11055/huge-action-space-size-in-reinforcement-learning
		
- Implementation of observation space
	==> Determine what our agent can observe. 
		--> Flow goals
		--> Flow states
		--> Network saturation, # collisions in past x time, avg saturation over past x time, ...
				>>> Many options!!

- Setup environment
	==> Initially, simple point to point link of some speed between two devices < total flow throughput
	==> By hand, determine optimal solution. Ensure RL finds it relatively quickly.

- Implementation of reward function
	- Check if need to add/subtract some stuff for partial completion